{"cells":[{"cell_type":"markdown","source":["# Describe the difference between eager and lazy execution"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b94b3918-cc42-47e1-b780-100c428afedf"}}},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Getting Started\n\nRun the following cell to configure our \"classroom.\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"448856a1-1a6b-40d4-9a17-686fa8c0780d"}}},{"cell_type":"code","source":["%run ./Includes/Classroom-Setup"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"165142ba-4fed-430f-a51a-5b34896457fd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Laziness By Design\n\nFundamental to Apache Spark are the notions that\n* Transformations are **LAZY**\n* Actions are **EAGER**\n\nThe following code condenses the logic from the DataFrames modules in this learning path, and uses the DataFrames API to:\n- Specify a schema, format, and file source for the data to be loaded\n- Select columns to `GROUP BY`\n- Aggregate with a `COUNT`\n- Provide an alias name for the aggregate output\n- Specify a column to sort on\n\nThis cell defines a series of **transformations**. By definition, this logic will result in a DataFrame and will not trigger any jobs."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b6e9cfb0-c8c4-44ce-9244-f03a5ac33a8d"}}},{"cell_type":"code","source":["schemaDDL = \"NAME STRING, STATION STRING, LATITUDE FLOAT, LONGITUDE FLOAT, ELEVATION FLOAT, DATE DATE, UNIT STRING, TAVG FLOAT\"\n\nsourcePath = \"/mnt/training/weather/StationData/stationData.parquet/\"\n\ncountsDF = (spark.read\n  .format(\"parquet\")\n  .schema(schemaDDL)\n  .load(sourcePath)\n  .groupBy(\"NAME\", \"UNIT\").count()\n  .withColumnRenamed(\"count\", \"counts\")\n  .orderBy(\"NAME\")\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1aa06034-501d-4441-8e35-cd93d5dec529"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Because `display` is an **action**, a job _will_ be triggered, as logic is executed against the specified data to return a result."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7c6c043b-a486-4d1f-979d-9b2f5bc0d64a"}}},{"cell_type":"code","source":["display(countsDF.limit(5))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"74b36d2a-dbeb-49f4-940b-9547ab3fe748"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["BARNABY CALIFORNIA, CA US","C",151],["BIG ROCK CALIFORNIA, CA US","C",151],["BLACK DIAMOND CALIFORNIA, CA US","C",151],["BRIONES CALIFORNIA, CA US","F",151],["CONCORD BUCHANAN FIELD, CA US","F",149]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"NAME","type":"\"string\"","metadata":"{}"},{"name":"UNIT","type":"\"string\"","metadata":"{}"},{"name":"counts","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>NAME</th><th>UNIT</th><th>counts</th></tr></thead><tbody><tr><td>BARNABY CALIFORNIA, CA US</td><td>C</td><td>151</td></tr><tr><td>BIG ROCK CALIFORNIA, CA US</td><td>C</td><td>151</td></tr><tr><td>BLACK DIAMOND CALIFORNIA, CA US</td><td>C</td><td>151</td></tr><tr><td>BRIONES CALIFORNIA, CA US</td><td>F</td><td>151</td></tr><tr><td>CONCORD BUCHANAN FIELD, CA US</td><td>F</td><td>149</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Why is Laziness So Important?\n\nLaziness is at the core of Scala and Spark.\n\nIt has a number of benefits:\n* Not forced to load all data at step #1\n  * Technically impossible with **REALLY** large datasets.\n* Easier to parallelize operations\n  * N different transformations can be processed on a single data element, on a single thread, on a single machine.\n* Optimizations can be applied prior to code compilation"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a7ab20bc-bb61-40b6-acce-5b253eaccccc"}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bc807313-bf21-4397-904a-2bde55d73f44"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"1.Eager-and-Lazy-execution","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3359981096916007}},"nbformat":4,"nbformat_minor":0}
